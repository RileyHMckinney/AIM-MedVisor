# -*- coding: utf-8 -*-
"""UNet Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dYWQakJeMrYlGs4qxYILUfkuceyv1qFN
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install SimpleITK numpy pillow

import zipfile
import os

# Define the paths to the zip files
images_zip_path = '/content/drive/MyDrive/Riley\'s Zipped Masks and Images/images2d.zip'
masks_zip_path = '/content/drive/MyDrive/Riley\'s Zipped Masks and Images/masks2d.zip'

# Define the extraction directories
input_img_dir = '/content/images2D'  # or any path you prefer
input_mask_dir = '/content/masks2D'   # or any path you prefer

# Create directories if they do not exist
os.makedirs(input_img_dir, exist_ok=True)
os.makedirs(input_mask_dir, exist_ok=True)

# Unzip images
with zipfile.ZipFile(images_zip_path, 'r') as zip_ref:
    zip_ref.extractall(input_img_dir)

# Unzip masks
with zipfile.ZipFile(masks_zip_path, 'r') as zip_ref:
    zip_ref.extractall(input_mask_dir)

print("Unzipping completed!")

import SimpleITK as sitk
import numpy as np
from PIL import Image
import os
import shutil
from itertools import permutations

# Set the correct input and output directories ####this needs to be changed to function within google collab
input_img_dir = r"/content/images2D"
input_mask_dir = r"/content/masks2D"
output_img_dir = r"/content/drive/MyDrive/LumbarDS/test_img"
output_mask_dir = r"/content/drive/MyDrive/LumbarDS/test_mask"

# Clear the contents of the output directories
def clear_output_directory(directory):
    if os.path.exists(directory):
        shutil.rmtree(directory)
    os.makedirs(directory, exist_ok=True)

clear_output_directory(output_img_dir)
clear_output_directory(output_mask_dir)

def save_slice_as_png(slice_data, output_path):
    """Normalize and save a 2D slice as PNG."""
    slice_data = (slice_data - np.min(slice_data)) / (np.max(slice_data) - np.min(slice_data)) * 255
    slice_data = slice_data.astype(np.uint8)

    # Ensure the longest dimension is vertical
    if slice_data.shape[1] > slice_data.shape[0]:
        slice_data = np.rot90(slice_data)

    Image.fromarray(slice_data).save(output_path)

def try_all_permutations(image):
    """Try all axis permutations and return the one with the largest area."""
    volume = sitk.GetArrayFromImage(image)  # Convert to numpy array
    max_area = 0
    best_slice = None

    # Test all possible permutations of the axes
    for perm in permutations([0, 1, 2]):
        permuted_image = sitk.PermuteAxes(image, list(perm))
        permuted_volume = sitk.GetArrayFromImage(permuted_image)

        # Check the shape of the middle slice along the first axis of the permuted volume
        middle_slice = permuted_volume[permuted_volume.shape[0] // 2, :, :]
        area = middle_slice.shape[0] * middle_slice.shape[1]  # Compute the area

        # Keep track of the largest area slice
        if area > max_area:
            max_area = area
            best_slice = middle_slice

    return best_slice

def convert_mha_to_largest_png(mha_file, output_dir):
    """Find and save the best 2D slice from all possible permutations of the MHA file."""
    try:
        # Read the 3D image file
        image = sitk.ReadImage(mha_file)

        # Find the best permutation with the largest slice area
        largest_slice = try_all_permutations(image)

        # Define the output path and save the slice
        filename = f"{os.path.basename(mha_file).split('.')[0]}.png"
        output_path = os.path.join(output_dir, filename)
        save_slice_as_png(largest_slice, output_path)

    except Exception as e:
        print(f"Error processing {mha_file}: {str(e)}")

# Process all MHA files in the images directory
if os.path.exists(input_img_dir):
    for file_name in os.listdir(input_img_dir):
        if file_name.endswith('.mha'):
            mha_path = os.path.join(input_img_dir, file_name)
            convert_mha_to_largest_png(mha_path, output_img_dir)

# Process all MHA files in the masks directory
if os.path.exists(input_mask_dir):
    for file_name in os.listdir(input_mask_dir):
        if file_name.endswith('.mha'):
            mha_path = os.path.join(input_mask_dir, file_name)
            convert_mha_to_largest_png(mha_path, output_mask_dir)

print("All images have been processed and saved.")

!pip install torch torchvision segmentation-models-pytorch numpy opencv-python pillow matplotlib

"""Create an instance of the ResNet Model"""

import torch
import torch.nn as nn
from segmentation_models_pytorch import Unet

# Create a U-Net model with a ResNet-34 encoder
def create_unet_model(num_classes=1, in_channels=3):
    model = Unet(
        encoder_name="resnet34",  # Choose encoder (e.g., resnet34)
        encoder_weights="imagenet",  # Use pre-trained ImageNet weights
        in_channels=in_channels,  # Number of input channels (3 for RGB)
        classes=num_classes,  # Number of output classes (1 for binary segmentation)
    )
    return model

# Instantiate the model
model = create_unet_model()
print(model)

import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image

class SpineDataset(Dataset):
    def __init__(self, images_dir, masks_dir, transform=None, target_size=(256, 256)):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.transform = transform
        self.target_size = target_size  # Resize to this size
        self.images = os.listdir(images_dir)  # Get list of all images

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        # Get image and mask paths
        img_path = os.path.join(self.images_dir, self.images[idx])
        mask_path = os.path.join(self.masks_dir, self.images[idx])  # Assume masks have same filenames

        # Load image and mask
        image = Image.open(img_path).convert("RGB").resize(self.target_size)  # Resize image
        mask = Image.open(mask_path).convert("L").resize(self.target_size)  # Resize mask

        # Normalize the pixel values to [0, 1]
        image = np.array(image) / 255.0
        mask = np.array(mask) / 255.0

        # Convert to PyTorch tensors
        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)  # [H, W, C] -> [C, H, W]
        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)  # [H, W] -> [1, H, W]

        return image, mask

# Define the paths to your 2D images and masks
images_dir = r"/content/images2D"
masks_dir = r"/content/masks2D"

# Create dataset and dataloader
train_dataset = SpineDataset(images_dir, masks_dir, target_size=(256, 256))  # Resize to 256x256
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)

print(f"Dataset size: {len(train_dataset)}")

import torch.nn as nn

# Define Dice Loss
def dice_loss(pred, target, smooth=1e-6):
    intersection = (pred * target).sum()
    union = pred.sum() + target.sum()
    return 1 - (2.0 * intersection + smooth) / (union + smooth)

# Combined BCE + Dice Loss
class BCEAndDiceLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, pred, target):
        bce_loss = self.bce(pred, target)
        dice = dice_loss(torch.sigmoid(pred), target)
        return bce_loss + dice

# Instantiate the loss function and optimizer
criterion = BCEAndDiceLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

"""Training loop for mask generation"""

import time

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)


# Training loop with timing
num_epochs = 10  # Adjust as needed
for epoch in range(num_epochs):
    start_time = time.time()  # Start timer

    model.train()
    running_loss = 0.0

    for images, masks in train_loader:
        images, masks = images.to(device), masks.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, masks)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    end_time = time.time()  # End timer
    epoch_time = end_time - start_time

    print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Time: {epoch_time:.2f}s")

print("Training complete.")

torch.save(model.state_dict(), r"C:\Users\TTG\Desktop\SPIDERdb\unet_spine_segmentation.pth")
print("Model state dictionary saved.")

"""Loads the pretrained U-Net model from above, runs it on a single image, converts the created mask to binary values, and prints the example for reference"""

import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# Load the trained model's state dictionary
model = create_unet_model()  # Initialize the model architecture
model.load_state_dict(torch.load(r"/content/drive/MyDrive/Colab Notebooks/models/unet_spine_segmentation.pth"))
model.eval()  # Set the model to evaluation mode

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

output_folder = r"/content/drive/MyDrive/mask_results"  # Folder to save the output image

def infer_and_visualize(model, image_path, save_folder=output_folder):
    """Run inference on a single image and display the input and predicted mask."""

    # Load and preprocess the image
    image = Image.open(image_path).convert("RGB").resize((256, 256))  # Resize to match training size
    image_np = np.array(image) / 255.0  # Normalize to [0, 1]

    # Convert to PyTorch tensor and move to device
    image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)

    # Run inference (disable gradient tracking)
    with torch.no_grad():
        output = model(image_tensor)
        predicted_mask = torch.sigmoid(output).cpu().numpy()[0, 0]

    # Convert the mask to binary (threshold of 0.5)
    binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255

    # Plot input image and predicted mask side by side
    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.imshow(image_np)
    plt.title("Input Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(binary_mask, cmap="gray")
    plt.title("Predicted Mask")
    plt.axis("off")

    plt.show()

# Save the plot if a save folder is provided
    if save_folder:
        # Ensure the folder exists
        os.makedirs(save_folder, exist_ok=True)

        # Generate the new filename by adding "result_" to the original filename
        base_filename = os.path.basename(image_path)
        save_filename = f"result_{base_filename}"
        save_path = os.path.join(save_folder, save_filename)

        # Save the figure
        plt.savefig(save_path, format='png', bbox_inches='tight')
        print(f"Output saved to {save_path}")


# Provide the path to your test image
test_image_path = r"/content/drive/MyDrive/training_images/196_t1.png"  #this is not an existing image as of now

# Run the inference and visualize
infer_and_visualize(model, test_image_path)

# import torch
# import numpy as np
# from PIL import Image, ImageDraw
# import matplotlib.pyplot as plt
# import cv2
# import os

# def infer_and_visualize(model, image_path, save_folder):
#     """Run inference on a single image and display the input, predicted mask, and mask with bounding boxes."""
#     # Load and preprocess the image
#     image = Image.open(image_path).convert("RGB").resize((256, 256))  # Resize to match training size
#     image_np = np.array(image) / 255.0  # Normalize to [0, 1]

#     # Convert to PyTorch tensor and move to device
#     image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)

#     # Run inference
#     with torch.no_grad():
#         output = model(image_tensor)
#         predicted_mask = torch.sigmoid(output).cpu().numpy()[0, 0]

#     # Convert the mask to binary (threshold of 0.5)
#     binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255

#     # Find contours in the binary mask
#     contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

#     # Convert mask to RGB to allow for color drawing
#     mask_with_boxes = np.stack([binary_mask] * 3, axis=-1)  # Make mask 3-channel
#     mask_with_boxes = Image.fromarray(mask_with_boxes)

#     # Draw bounding boxes on the mask
#     draw = ImageDraw.Draw(mask_with_boxes)
#     for contour in contours:
#         x, y, w, h = cv2.boundingRect(contour)  # Get bounding box for each contour
#         # Draw rectangle or circle
#         draw.rectangle([x, y, x + w, y + h], outline="red", width=2)  # Draw bounding box

#     # Define the output filename based on the input filename
#     filename = f"result_{os.path.basename(image_path)}"
#     save_path = os.path.join(save_folder, filename)

#     # Save the mask with bounding boxes
#     mask_with_boxes.save(save_path)

#     # Display the original image, binary mask, and mask with bounding boxes
#     plt.figure(figsize=(18, 6))

#     plt.subplot(1, 3, 1)
#     plt.imshow(image_np)
#     plt.title("Input Image")
#     plt.axis("off")

#     plt.subplot(1, 3, 2)
#     plt.imshow(binary_mask, cmap="gray")
#     plt.title("Predicted Mask")
#     plt.axis("off")

#     plt.subplot(1, 3, 3)
#     plt.imshow(mask_with_boxes)
#     plt.title("Mask with Bounding Boxes")
#     plt.axis("off")

#     plt.show()

# # Define output folder and test image path
# output_folder = "/content/drive/MyDrive/mask_results"
# os.makedirs(output_folder, exist_ok=True)
# # test_image_path = "/content/drive/MyDrive/training_images/134_t2.png"  # Example image path

# # Run inference, visualize, and save the result with bounding boxes
# infer_and_visualize(model, test_image_path, save_folder=output_folder)

"""Runs similar code again, now with added snippet for creating bounding boxes."""

import torch
import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import cv2
import os

def infer_and_visualize(model, image_path, save_folder, height_threshold=50):
    """Run inference on a single image and display the input, predicted mask, and mask with bounding boxes."""
    # Load and preprocess the image
    image = Image.open(image_path).convert("RGB").resize((256, 256))  # Resize to match training size
    image_np = np.array(image) / 255.0  # Normalize to [0, 1]

    # Convert to PyTorch tensor and move to device
    image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)

    # Run inference
    with torch.no_grad():
        output = model(image_tensor)
        predicted_mask = torch.sigmoid(output).cpu().numpy()[0, 0]

    # Convert the mask to binary (threshold of 0.5)
    binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255

    # Find contours in the binary mask
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Convert mask to RGB to allow for color drawing
    mask_with_boxes = np.stack([binary_mask] * 3, axis=-1)  # Make mask 3-channel
    mask_with_boxes = Image.fromarray(mask_with_boxes)

    # Draw bounding boxes on the mask with height filtering
    draw = ImageDraw.Draw(mask_with_boxes)
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)  # Get bounding box for each contour

        # Skip contours with height larger than the threshold
        if h < height_threshold:
            # Draw rectangle only if it meets the height condition
            draw.rectangle([x, y, x + w, y + h], outline="red", width=2)

    # Define the output filename based on the input filename
    filename = f"result_{os.path.basename(image_path)}"
    save_path = os.path.join(save_folder, filename)

    # Save the mask with bounding boxes
    mask_with_boxes.save(save_path)

    # Display the original image, binary mask, and mask with bounding boxes
    plt.figure(figsize=(18, 6))

    plt.subplot(1, 3, 1)
    plt.imshow(image_np)
    plt.title("Input Image")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(binary_mask, cmap="gray")
    plt.title("Predicted Mask")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(mask_with_boxes)
    plt.title("Mask with Bounding Boxes")
    plt.axis("off")

    plt.show()

# Define output folder and test image path
output_folder = "/content/drive/MyDrive/mask_results"
os.makedirs(output_folder, exist_ok=True)
# test_image_path = "/content/drive/MyDrive/training_images/203_t2.png"  # Example image path

# Run inference, visualize, and save the result with bounding boxes
infer_and_visualize(model, test_image_path, save_folder=output_folder, height_threshold=50)

"""Placing the Bounding Boxes onto the Original Lumbar Spine MRI"""

import torch
import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import cv2
import os

def infer_and_visualize(model, image_path, save_folder):
    """Run inference on a single image and display the input, predicted mask, and mask with bounding boxes."""
    # Load and preprocess the image
    image = Image.open(image_path).convert("RGB").resize((256, 256))  # Resize to match training size
    original_image = Image.open(image_path).convert("RGB")  # Original size for overlay
    image_np = np.array(image) / 255.0  # Normalize to [0, 1]

    # Convert to PyTorch tensor and move to device
    image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)

    # Run inference
    with torch.no_grad():
        output = model(image_tensor)
        predicted_mask = torch.sigmoid(output).cpu().numpy()[0, 0]

    # Convert the mask to binary (threshold of 0.5)
    binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255

    # Find contours in the binary mask
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Draw bounding boxes on the mask and original image
    mask_with_boxes = np.stack([binary_mask] * 3, axis=-1)  # Make mask 3-channel
    mask_with_boxes = Image.fromarray(mask_with_boxes)
    draw_mask = ImageDraw.Draw(mask_with_boxes)
    draw_original = ImageDraw.Draw(original_image)

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        if h < 100:  # Adjust this threshold based on the height condition you used
            # Draw bounding box on the mask
            draw_mask.rectangle([x, y, x + w, y + h], outline="red", width=2)
            # Draw bounding box on the original image
            draw_original.rectangle([x, y, x + w, y + h], outline="red", width=2)

    # Save the mask with bounding boxes and the original image with bounding boxes
    filename_mask = f"mask_with_boxes_{os.path.basename(image_path)}"
    filename_original = f"original_with_boxes_{os.path.basename(image_path)}"
    # save_path_mask = os.path.join(save_folder, filename_mask)
    # save_path_original = os.path.join(save_folder, filename_original)

    # mask_with_boxes.save(save_path_mask)
    # original_image.save(save_path_original)

    # Display the images
    plt.figure(figsize=(18, 6))

    plt.subplot(1, 3, 1)
    plt.imshow(image_np)
    plt.title("Input Image")
    plt.axis("off")

    plt.subplot(1, 3, 2)
    plt.imshow(binary_mask, cmap="gray")
    plt.title("Predicted Mask")
    plt.axis("off")

    plt.subplot(1, 3, 3)
    plt.imshow(original_image)
    plt.title("Original Image with Bounding Boxes")
    plt.axis("off")

    plt.show()

# Define output folder and test image path
output_folder = "/content/drive/MyDrive/mask_results"
os.makedirs(output_folder, exist_ok=True)
test_image_path = "/content/drive/MyDrive/training_images/203_t2.png"  # Example image path

# Run inference, visualize, and save the result with bounding boxes
infer_and_visualize(model, test_image_path, save_folder=output_folder)





import torch
import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import cv2
import os

def infer_and_visualize(model, image_path, save_folder):
    """Run inference on a single image and display the input, predicted mask, and mask with bounding boxes."""
    # Load the original image
    original_image = Image.open(image_path).convert("RGB")
    original_size = original_image.size  # Get original image size (width, height)

    # Load and preprocess the image for model input
    image = original_image.resize((256, 256))  # Resize to match training size
    image_np = np.array(image) / 255.0  # Normalize to [0, 1]

    # Convert to PyTorch tensor and move to device
    image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)

    # Run inference
    with torch.no_grad():
        output = model(image_tensor)
        predicted_mask = torch.sigmoid(output).cpu().numpy()[0, 0]

    # Convert the mask to binary (threshold of 0.5)
    binary_mask = (predicted_mask > 0.5).astype(np.uint8) * 255

    # Find contours in the binary mask
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Create a draw object for the original image
    draw_original = ImageDraw.Draw(original_image)

    # Calculate scaling factors
    scale_x = original_size[0] / 256.0
    scale_y = original_size[1] / 256.0

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        if h < 100:  # Adjust this threshold based on the height condition you used
            # Scale bounding box coordinates back to original image size
            x = int(x * scale_x)
            y = int(y * scale_y)
            w = int(w * scale_x)
            h = int(h * scale_y)

            # Draw bounding box on the original image
            draw_original.rectangle([x, y, x + w, y + h], outline="red", width=2)

    # Save the original image with bounding boxes
    filename_original = f"original_with_boxes_{os.path.basename(image_path)}"
    save_path_original = os.path.join(save_folder, filename_original)
    original_image.save(save_path_original)

    # Display the images
    plt.figure(figsize=(18, 6))

    plt.subplot(1, 2, 1)
    plt.imshow(image_np)
    plt.title("Input Image")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(original_image)
    plt.title("Original Image with Bounding Boxes")
    plt.axis("off")

    plt.show()

# Define output folder and test image path
output_folder = "/content/drive/MyDrive/mask_results"
os.makedirs(output_folder, exist_ok=True)
test_image_path = "/content/drive/MyDrive/training_images/203_t2.png"  # Example image path

# Run inference, visualize, and save the result with bounding boxes
infer_and_visualize(model, test_image_path, save_folder=output_folder)

